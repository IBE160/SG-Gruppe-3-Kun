# Epic 2: Core Conversational Experience & RAG Pipeline - Retrospective Summary

**Date:** Sunday, 14 December 2025
**Facilitator:** Bob (Scrum Master)
**Participants:** BIP (Project Lead), Alice (Product Owner), Charlie (Senior Dev), Dana (QA Engineer), Elena (Junior Dev), Amelia (Dev Agent)

---

## üîÑ Epic 2 Summary & Status

Epic 2, "Core Conversational Experience & RAG Pipeline," is complete. This epic delivered the "magic" of the product: a working RAG pipeline, a responsive chat interface, and real-time streaming answers with citations.

**EPIC 2 Delivery Metrics:**
*   **Completed Stories:** 7/7 (100%)
*   **Final Status:** All stories marked 'done' in sprint-status.
*   **Timeline:** Delivered on schedule, despite technical challenges with new libraries.

**Quality and Technical Overview:**
*   **Blockers Encountered:** Significant dependency conflicts with `pydantic-ai` and `langchain-google-genai`.
*   **Technical Debt:** `pydantic-ai` versioning is currently managed ad-hoc; Playwright configuration is inconsistent across stories.
*   **Test Coverage:** High unit test coverage; Integration/E2E tests were added late but are now present for critical flows.
*   **Production Readiness:** The RAG pipeline is functional and grounded. Citations provide necessary trust.

**Business Outcomes:**
*   **Goals Achieved:** Users can now chat with the documentation and get accurate, cited answers.
*   **Stakeholder Acceptance:** The "streaming" effect and citations have been particularly well-received for building trust.

---

## ‚úÖ What Went Well

*   **RAG Pipeline Success:** Despite complexity, the core RAG logic (Ingestion -> ChromaDB -> Pydantic AI -> Gemini) works. The decision to use `pydantic-ai` for structured output proved correct for reliability.
*   **UI/UX Implementation:** The responsive 3-column desktop and tabbed mobile layouts were implemented cleanly and match the design specs perfectly.
*   **Streaming Implementation:** The SSE implementation (Backend `StreamingResponse` + Frontend `useChat`) provides a polished, professional user feel.
*   **Citations:** Successfully extracting and linking sources builds immediate trust in the tool.

---

## ‚ö†Ô∏è What Didn't Go Well / Challenges

*   **Dependency Hell (Pydantic AI):** We faced repeated issues with `pydantic-ai` versions.
    *   Story 2.3 required removing `langchain-google-genai` to fix conflicts.
    *   Story 2.4 required unpinning/upgrading to `1.32.0` to fix execution errors.
    *   *Impact:* Lost time debugging environment and package issues.
*   **Testing Inconsistency:**
    *   Story 2.4 was initially blocked due to missing E2E tests.
    *   Story 2.5 skipped E2E tests citing "Playwright not configured," despite Story 2.4 having added them.
    *   *Impact:* Confusion about the state of the test infrastructure.
*   **Tech Spec Visibility:** The reviewer for Story 2.1 noted "No Epic 2 Tech Spec available," even though the file `tech-spec-epic-2.md` existed (dated Dec 8). This suggests a breakdown in artifact discovery or communication.

---

## üí° Key Insights & Learnings

1.  **Bleeding Edge Risks:** `pydantic-ai` is powerful but fast-moving. We need a stricter strategy for managing its version updates to avoid breaking builds mid-sprint.
2.  **Test Infrastructure as Code:** We cannot rely on implicit knowledge about test setups. If Playwright is set up in Story 2.4, Story 2.5's dev needs to know that. We need to better broadcast infrastructure capabilities.
3.  **Artifact Verification:** Simply creating a Tech Spec isn't enough; we must ensure the Dev Agents *find* and *read* it before starting work.

---

## üìù EPIC 2 ACTION ITEMS (Commitments)

**Technical & Process:**

1.  **Standardize Pydantic AI Version:**
    *   **Description:** Lock `pydantic-ai` to a specific stable version in `pyproject.toml` and document the upgrade procedure.
    *   **Owner:** Charlie (Senior Dev) / Amelia
    *   **Timeline:** Before Epic 3 implementation starts.

2.  **Audit & Fix Playwright Config:**
    *   **Description:** Verify Playwright configuration is global and accessible to all stories. Create a standardized E2E test helper if needed.
    *   **Owner:** Dana (QA)
    *   **Timeline:** Before Epic 3 testing tasks.

3.  **Tech Spec Handoff Protocol:**
    *   **Description:** Scrum Master must explicitly verify that the Dev Agent has loaded the Epic Tech Spec in the "Context Reference" section of the first story of an epic.
    *   **Owner:** Bob (Scrum Master)
    *   **Timeline:** Effective immediately for Epic 3.

---

## üöÄ PREPARATION FOR EPIC 3 (User Context)

Epic 3 involves "User Context & Personalization".

**Readiness Check:**
*   **Tech Spec:** `tech-spec-epic-3.md` exists. **Action:** Verify its content is complete.
*   **Backend Support:** `ChatRequest` model in Story 2.3 already includes `role: Optional[str]`. **Status:** Ready.
*   **Frontend Support:** `ChatWindow` needs to be updated to capture role *before* chatting. **Status:** Planned in Story 3.1.
*   **RAG Prompt:** `chat_service.py` needs to use the passed role. **Status:** Planned in Story 3.3.

**Critical Path:**
1.  Ensure `tech-spec-epic-3.md` is reviewed by the team.
2.  Confirm `pydantic-ai` version is stable for the prompt engineering work in Epic 3.

---

## ‚úÖ Epic 2 Readiness Assessment Summary

*   **Testing & Quality:** Verified (Unit + Integration + partial E2E).
*   **Deployment:** CI/CD pipeline from Epic 1 is deploying Epic 2 changes successfully.
*   **Stakeholder Acceptance:** High.
*   **Technical Health:** Stable, with known dependency management debt.

Epic 2 is **Complete**.
